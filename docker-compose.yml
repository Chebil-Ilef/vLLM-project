services:
  neo4j:
    image: neo4j:5.11
    container_name: bia_neo4j
    environment:
      - NEO4J_AUTH=neo4j/test
    volumes:
      - neo4j_data:/data
    ports:
      - '7474:7474'
      - '7687:7687'

  backend:
    build:
      context: ./chatbot-system
      args:
        USE_VLLM: ${USE_VLLM:-0}
    container_name: bia_backend
    env_file:
      - ./chatbot-system/.env
    environment:
      - FLASK_ENV=production
    ports:
      - '5000:5000'
    depends_on:
      - neo4j
      - vllm
    volumes:
      - ./chatbot-system:/app

  frontend:
    build: ./frontend
    container_name: bia_frontend
    ports:
      - '8080:8080'
    depends_on:
      - backend

  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm_server
    ports:
      - "8001:8000"
    environment:
      VLLM_API_KEY: devkey
    command: >
      --model mistralai/Mistral-7B-Instruct-v0.3
      --dtype auto
      --api-key devkey
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

volumes:
  neo4j_data:
